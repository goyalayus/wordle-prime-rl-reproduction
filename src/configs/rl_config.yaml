model:
  name: "unsloth/qwen3-4b-unsloth-bnb-4bit"
  max_seq_length: 4096
  load_in_4bit: true
  fast_inference: true
  init_adapter_repo: "goyalayus/wordle-lora-qwen3-4b"
  init_adapter_revision: "step-1320"

lora:
  r: 16
  alpha: 32
  dropout: 0.0
  bias: "none"
  target_modules: ["up_proj", "gate_proj", "down_proj"]
  gradient_checkpointing: "unsloth"

vllm:
  enabled: true
  gpu_memory_utilization: 0.9
  temperature: 1.0
  min_p: 0.1
  top_p: 1.0
  top_k: -1
  max_tokens: 2048

training:
  seed: 3407
  max_steps: 1000
  per_device_batch_size: 1
  gradient_accumulation_steps: 4
  learning_rate: 5.0e-6
  optim: "adamw_8bit"
  num_generations: 4
  max_prompt_length: 2048
  max_completion_length: 2048
  run_name: "wordle_rl_vllm_config_test"
  output_dir: "./outputs/rl_grpo"
  report_to: ["wandb"]
  hf_repo_id: ""

task:
  synthetic_samples: 4096
  min_history_turns: 1
  max_history_turns: 4
  wordlists:
    solutions: "qwen4b-lora-wordle/RL/wordlists/wordle_solutions.txt"
    allowed: "qwen4b-lora-wordle/RL/wordlists/wordle_allowed_guesses.txt"
  rewards:
    format: 0.2
    dict: 0.2
    repeat_penalty: -0.5
    constraint: 0.1
    overlength_penalty: -0.5
